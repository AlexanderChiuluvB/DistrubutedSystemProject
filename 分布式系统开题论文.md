## 分布式系统课程项目——电商秒杀模拟


### 1. 秒杀业务目标分析

- 一致性：库存量少，一般秒杀请求量远远大于库存数量，因此在大并发更新的时候要防止超卖现象发生。

- 高可用：系统能够抗住大量的流量同时保证不宕机。即使部分节点宕机也能保证正常工作

- 透明性

  - 访问透明性、位置透明性、移动透明性：由http协议和Internet、Ethernet可以自动实现。

  - 性能透明性：秒杀涉及大量并发读和并发写，而且网络流量暴增，网络带宽压力会加大，所以要支持高并发访问。当负载爆发式加重时，服务端可以自动配置以提高性能。
  - 并发透明性：大量的请求线程不能互相干扰。这是系统设计的核心部分。
  - 伸缩透明性：当服务器性能升级，或者增加若干台服务器时，性能可以近似线性增长。
  - 故障透明性：当某个服务器发生故障，不会导致服务彻底崩溃，有一定的容错机制

- 业务流程简单：下购买订单->数据库库存减少->响应客户->客户支付订单

- 读多写少：大量的HTTP请求都是读请求，写请求即更改数据库的请求占相对少数，因此提高数据库的读取速度将是性能提升的一关键。

### 2. 架构设计思路

所有措施的根本目的都是为了把请求尽量拦截在上游，尽可能减少对MYSQL数据库的访问。

- 限流

根据现有服务器的处理能力，限制超载流量，使得爆发式的流量在服务前端就被拒绝，使得进入任何中间件和其他后端服务器的流量尽可能少。

具体实现: Redis令牌桶限流算法，Redis抗住绝大部分无用请求

- 削峰

秒杀请求在时间上高度集中于某一个时间点，瞬时流量容易冲垮系统。因此需要对瞬时流量进行削峰处理，缓冲瞬时流量，对时间进行解耦合，尽量让服务器对资源进行平缓处理

具体实现：大量下单请求先经过Kafka队列入队，然后再缓慢出队。

- 异步

把同步的下单请求改为异步，提高并发量，本质上也是削峰操作

具体实现：Redis成功预减库存后，新开一个线程发送给Kafka

- 充分利用缓存

创建订单的时候，每次都需要查询Redis判断库存是否足够。只有少部分成功的请求才会创建订单。

具体实现：可以把商品信息放在Redis缓存中，减少数据库查询。

- 负载均衡

利用Nginx等使用多个服务器并发处理请求，以减少单个服务器的压力.

### 3. 高并发下的数据安全与解决方案

- 超卖现象

假设某个抢购场景中，我们一共只有100个商品，在最后一刻，我们已经消耗了99个商品，仅剩最后一个。这个时候，系统发来多个并发请求，这批请求读取到的商品余量都是1个，然后都通过了这一个余量判断，最终导致超卖，这是我们要极力避免的现象。

#### 解决方案分析

- MySQL事物隔离级别：

  ​	在数据库理论中，事物的隔离性（Isolation）与数据库的事物吞吐量存在权衡（trade-off）。过于严格的事物隔离性，可以绝对保证ACID，但是对吞吐量限制太大，可用于要求严格一致性的事物，例如银行系统。但是对于本项目，会导致秒杀延迟极大，故不适用。因此，基于不同的适用过程，MySQL提出了四种事物隔离级别，适用于不同场景。

  - **未提交读**（READ UNCOMMITTED）：不要求事物隔离性，可能导致脏读。这种无隔离性不适用于购物系统。
  - **已提交读**（READ COMMITTED）：有一定的事物隔离性，避免了脏读，一个线程不能读取另外一个线程未提交的事物。存在幻读的问题。
  - **可重复读**（REPEATABLE READ）：更强的事物隔离性。采用了MVCC(Multi-Version Concurrency Control)的机制，实际上就是一种乐观锁理念的实现。线程A读操作不会更新版本号，此时其它线程修改了数据，即使提交了也不会为线程A读到。线程读不会更新版本号，所以读的都是历史版本，写的时候会更新版本号到最新版本，写时无法满足一致性条件（merge失败）会被放弃。部分解决了幻读的问题。同时这也是MySQL默认的事务隔离级别。
  - **可串行化**（SERIALIZABLE）：无论读写直接锁表，其他操作无法进行，某时刻表有唯一的使用者。并发度为1。完全解决了幻读的问题。数据一致性达到了绝对的保障。

- 基于Redis的分布式锁

  Redis的设计模式中是不支持事务的，但是从Redis的官方文档中，我们可以得知，要在Redis中实现事物的ACID特性，可以利用lua脚本来实现。Redis提供API,`call`来以原子性的操作来执行lua脚本。这意味着，要在分布式环境下实现事物的特性，需要由程序员从算法上来设计。

  Redis中实现事务性普遍通过CAS(Compare And Set)的方式来进行设计，同时设置超时时间避免死锁。

  在我们的架构中，最终采用了基于Redis的框架Redisson来实现分布式锁，Redisson的实现原理在后文详述。

- 基于Zookeeper的分布式锁

主要利用了Zookeeper文件系统的Znode.上锁就是某个节点尝试创建临时的znode，创建成功了就相当于获取这个锁。

这个时候如果别的客户端来尝试创建锁就会失败，所以只能注册一个监听器来监听这个锁。释放锁就是删除这个znode，一旦释放掉就会通知客户端，然后有一个等待着的客户端就可以重新加锁。

理论上，Redis是基于CAS，需要自己不断去尝试获取锁，比较消耗CPU性能。

但是Zk分布式锁如果获取不到锁，只需要注册一个监听器即可，不需要不断主动尝试获取锁，性能开销相对较小。

而且Zk分布式锁的语义更为清晰简单，省去了遍历上锁，计算超时时间的步骤。

```
  CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().
                connectString("172.101.8.4").
                retryPolicy(policy).
                build();
  curatorFramework.start();
  //Zookeeper的锁,尝试创建一个znode节点"myMutex"
  mutex = new InterProcessMutex(curatorFramework, "/myMutex");
```
Then before get access to redis, we use mutex.acquire() to get the zk lock, finally we release the lock when the transaction is finished.




### 4. Architecture Design


#### 4.1 架构改进前：

![架构改进前](https://raw.githubusercontent.com/gongfukangEE/gongfukangEE.github.io/master/_pic/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%BC%93%E5%86%B2.png)

- 请求首先到达一个Portal Server，在这里，通过令牌桶算法限制最大流量，之后通过Nginx反向代理将请求哈希到若干Server；
- 查询Redis库存，如果非空，进入消息队列；
- 从kafka出队后用基于乐观锁机制更新Mysql，版本号合理，秒杀成功，然后更新Redis;
- 版本号过期，秒杀失败

解决超卖的关键：Mysql基于版本号的乐观锁

性能瓶颈：MySQL更新速度慢，大量无效请求

##### 架构评估：

- 吞吐量低：我们在测试中发现，有大量重复的版本号会导致请求失败，但是磁盘已经承受了相应的任务，这意味着我们对磁盘的利用是非常不合理的，在有限的时间内，大量的I/O操作没有用于更新库存，创建订单，反而用来确认无效订单。
- 并发控制策略选取：我们选取了基于MySQL的手工乐观锁的并发控制，然而乐观锁并不适合大规模的写操作。虽然在我们的场景中写的操作相对读操作的次数是较少的，但是绝对数上来看仍然是多的，不适用于乐观并发控制，会导致大量事物回滚。
- 中间件性能浪费：大量无效请求消耗了Redis, Kafka, MySQL中间件的性能，这就意味着，服务集群的CPU、内存和外存资源被无效的事物逻辑支配。例如，某时刻100个请求涌入服务器，读到版本号均为1，Redis库存此时对所有请求的视图都是一致的；如果非空，这100个请求都可以进入kafka消息队列，但只有最先出队并更新MySQL的可以成功执行，下单成功，剩下的99个请求都会因为版本号过期而被放弃，而此时库存仅仅被消耗了1件，但是中间件和服务器都已经承担了100个请求的工作量。这一问题在并发量进一步增高的时候会更明显。
- 超卖现象：
  - 对于MySQL使用了默认级别的事物隔离，即**可重复读**，这意味着请求在读取版本号的时候，很可能不是最新的版本号，写的时候就会写失效，返回给用户和Redis错误信息。
  - 后续我们修改了MySQL的事物隔离级别为**已提交读**，仍然存在问题。已提交读是不锁表的。例如，库存剩下1件，两个同样版本号的事物，一个事物开启减库存未提交，另一个事物读取的时候发现仍有库存版本号也合适，也进入事物开始更新，此时前一个事物提交，后一个事物更新时候发现版本号错误。对于后一个事物来说，读时版本号通过，写时发现版本号不错，只会写无效，返回给用户和Redis错误的信息，也是不可取的。
  - 在这种情况下，只有最后一种选择，**可串行化**。当我们设置隔离级别为可串行化时，吞吐量再次大幅下跌。
- 单点故障：一旦出现故障，处理能力线性降低，关键性的节点同时宕机（例如Redis主机和所有从机），系统瘫痪。
- Redis限流功能受限：没有充分利用Redis。一方面，Redis的作用仅仅在于令牌桶过滤部分请求，可以利用有限资源控制流量，以及所有商品售完后用来挡住后续的秒杀请求。秒杀完成之前，Redis的存在甚至有一些冗余。另一方面，Redis同时被前端请求和后端请求更新，也造成了非常忙碌的状态

#### 4.2 架构改进后：

![image-20191214135650932](%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%BC%80%E9%A2%98%E8%AE%BA%E6%96%87.assets/image-20191214135650932.png)

- 请求首先到达一个Portal Server，在这里，通过令牌桶算法限制最大流量，之后通过Nginx反向代理将请求哈希到若干Server；
- 每个Server按照硬件处理能力预置好一定量的本地库存，同时额外增加一定量的buffer，避免单个服务器故障之后由于本地库存总量减少，商品无法卖出；
- Redis集群分布式部署在多个性能优良的节点上，实现读写分离，各个服务器的线程连接集群尝试异步更新；
- Redis更新成功后会立即返回给用户使用户得到响应为订单创建成功，同时开启后台线程将订单信息送进消息队列kafka
- kafka后台线程不断从消息队列中获得消息，构造环境，将信息同步至MySQL,事物隔离级别为可重复读即可。

解决超卖的关键：秒杀开始前，Redis同步MySQL的库存量，Redis分布式锁保证Redis库存更新以事物的级别处理

性能瓶颈：接口分发服务器的带宽有限，在无限带宽的前提下，Redis分布式锁为性能瓶颈

有待继续改进地方：当并发量到达一个10^7/s时，偶尔会出现超卖现象，即Redisson分布式锁失效。

解决方案：对于概率极小的超卖现象，我们在MySQL处发现异常时对相应订单进行回滚并通知客户，这是一种折中的方式。

##### 架构评估：



### 5. Middleware-Redis

#### 5.1 Introduction to Redis

Redis is an in-memory data structure store, used as a database, cache and message broker. It supports various data structures. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.

#### 5.2 Redis on-disk persistence

Redis的主要工作位于内存，为了保护内存中数据的非易失性，Redis采用两种持久化策略保存数据。以下将简要分析两种策略，并解释本项目中的选取。

##### 5.2.1 RDB

The RDB persistence performs point-in-time snapshots of your dataset at specified intervals.

根据设置，RDB方法将在每t时间间隔检查写的次数是否超过n，超过的话就执行一次持久化

<img src="%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%BC%80%E9%A2%98%E8%AE%BA%E6%96%87.assets/image-20191214175536375.png" alt="image-20191214175536375" style="zoom:30%;" />

Whenever Redis needs to dump the dataset to disk, this is what happens:

- Redis forks. We now have a child and a parent process.
- The child starts to write the dataset to a temporary RDB file.
- When the child is done writing the new RDB file, it replaces the old one.

RDB的持久化可以选择通过后台进程进行的，目的是为了维护异步性。但是创建进程（fork）仍然有巨大的开销。同时，要注意到RDB的持久化策略采取的是全量同步。

##### 5.2.2 AOF

The AOF persistence logs every write operation received by the server, that will be played again at server startup, reconstructing the original dataset. Commands are logged using the same format as the Redis protocol itself, in an append-only fashion. Redis is able to rewrite the log in the background when it gets too big.

<img src="%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%BC%80%E9%A2%98%E8%AE%BA%E6%96%87.assets/image-20191214181125138.png" alt="image-20191214181125138" style="zoom:33%;" />

- Redis forks, so now we have a child and a parent process.
- The child starts writing the new AOF in a temporary file.
- The parent accumulates all the new changes in an in-memory buffer (but at the same time it writes the new changes in the old append-only file, so if the rewriting fails, we are safe).
- When the child is done rewriting the file, the parent gets a signal, and appends the in-memory buffer at the end of the file generated by the child.
- Now Redis atomically renames the old file into the new one, and starts appending new data into the new file.

AOF的重写操作有几种策略：每次更新重写、每秒重写、完全不重写。

AOF的持久化虽然也是通过后台进行的，但可以看到，后台进程重写AOF文件时，主进程也要受到很大影响（将记录写进aof_buf和aof_rewrite_buf）。子进程创建时的fork操作也同样有较大开销。另一方面，与RDB不同，AOF采取的同步策略是增量同步。

##### 5.2.3 Comparation and Selection

比较两种同步方式，我们认为在秒杀系统中应当使用RDB的持久化方式，若干秒（>=5~10）同步一次，理由如下：

- 相比于AOF，同步时对于主进程的影响较少
- 相比于AOF，不会在每次更新时保留日志记录，影响Redis吞吐率
- AOF的同步子进程会根据log重建数据，占用在秒杀系统中，非常珍贵的CPU资源
- 相比于AOF，有对流量波峰波谷的自动调控
- 由于Redis主从复制的模式就是log-based，再主动在本地磁盘写入AOF略显冗余

配置文件设置如下：

```
# 时间策略
save 10 1
save 600 10000
save 3600 10000

# 文件名称
dbfilename dump.rdb

# 文件保存路径
dir $HOME/redis-cluster/8001/data/

# 如果持久化出错，主进程是否停止写入
stop-writes-on-bgsave-error yes

# 是否压缩
rdbcompression no

# 导入时是否检查
rdbchecksum no

# 是否开启aof
appendonly no
```

虽然如此，如果所售货物价值较高，要在整个售卖流程中需要严格监控的，应采用每次query进行AOF增量同步的模式。

#### 5.3 Redis Cluster

##### 5.3.1 Redis Cluster Abilities

Redis Cluster provides a way to run a Redis installation where data is **automatically sharded across multiple Redis nodes**.

Redis Cluster also provides **some degree of availability during partitions**, that is in practical terms the ability to continue the operations when some nodes fail or are not able to communicate. However the cluster stops to operate in the event of larger failures (for example when the majority of masters are unavailable).

In conclusion, the abilities of Redis include

- **automatically spliting your dataset among multiple nodes**.
- **continuing operations when a subset of the nodes are experiencing failures** or are unable to communicate with the rest of the cluster.

The graph below shows our configuration on Redis Cluster.

<img src="%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%BC%80%E9%A2%98%E8%AE%BA%E6%96%87.assets/image-20191215114430222.png" alt="image-20191215114430222" style="zoom:47%;" />

##### 5.3.2 Redis Cluster Communication

Every Redis Cluster node requires two TCP connections open. The normal Redis TCP port used to serve clients while the second port is used for the Cluster bus, that is a node-to-node communication channel using a binary protocol. The Cluster bus is used by nodes for failure detection, configuration update, failover authorization and so forth.

In our project, port 8001-8006 are for clients, while port 18001-18006 are for internal communication.

##### 5.3.3 Redis Cluster Data sharding

Redis Cluster does not use consistent hashing, but a different form of sharding where every key is conceptually part of what we call an **hash slot**.

There are 16384 hash slots in Redis Cluster, and to compute what is the hash slot of a given key, we simply take the CRC16 of the key modulo 16384. Every node in a Redis Cluster is responsible for a subset of the hash slots.

Below is our configuration about redis cluster:

![image-20191214191807685](%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%BC%80%E9%A2%98%E8%AE%BA%E6%96%87.assets/image-20191214191807685.png)

##### 5.3.4 Redis主从复制

1. 从服务器初始化
   　　当从服务器启动时，会向主服务器发送SYNC命令，请求同步数据。主服务器接收到消息之后，进行RDB持久化，并生成一个快照文件；与此同时，主服务器会将生成快照期间新执行的命令缓存起来。在快照文件生成完毕之后，主服务器将RDB快照文件和缓存下来的命令一并发送给从服务器，从服务器首先载入接收到的RDB快照文件，接着执行被缓存下来的新命令，完成主从数据的初始化同步操作。
2. 从服务器保持同步
   　　从服务器在同步完成之后，主服务器接收到的所有命令都会异步的发送给从服务器用来保持主从数据的一致性。以此来实现Redis读写分离，读操作作用于Slave节点，写操作作用于Master节点。
3. 从服务器故障后处理
   　　当从服务器崩溃之后，重启之后进行初始化，会自动的同步主服务器的数据。此时redis采用了增量复制的方式从服务器的初始化同步数据的过程。
4. 主服务器故障后处理
   　　当主服务器崩溃之后，选举算法将选择一个从服务器升级为主服务器。

In our project, the classical pattern of 3 master with 3 slaves is adopted.

##### 5.3.5 Redis Sentinel

​	哨兵是一个独立于数据服务器的进程，用于监控redis数据服务器的状态，当主从模式下最关键的主服务器出现故障时，能够被哨兵自动的察觉。同时哨兵会在剩余的从服务器中**"选举"**出新的主服务器，达到自动化恢复系统服务的目的.

​	哨兵启动时会与主服务器建立连接，并且间接的获得所属从服务器信息，完成哨兵的初始化。哨兵初始化完成之后，会周期性的和主从服务器、其它哨兵节点(通过消息频道的订阅/发布)进行通信。

　哨兵每10秒会向所有服务器发送一次**INFO**命令，获得相关redis服务器的当前状态以便决定是否需要故障恢复。

　当一个哨兵在**down-after-milliseconds**规定时间内未收到主服务器的响应，则当前哨兵**"主观"**认为主服务器下线，同时和监视当前系统的其它哨兵进行投票决定，当超过当前哨兵配置中投票决定的数目时，则当前哨兵**"客观"**认为主服务器下线，哨兵集群会选举出领导哨兵来进行主从服务器集群主从状态的切换(使用Raft算法)。

​	Below shows how our project configures sentinel:

```
//监控master
sentinel monitor "master" "172.101.8.2" "18001"　

//确认连接密码
sentinel auth-pass "master" 123456

//设置宕机时长
sentinel down-after-milliseconds "500"　

//每次发生宕机，只有一个slave不继续参与命令处理
sentinel parallel-syncs "master" 1 
```

一方面，在秒杀系统带宽及其珍贵，我们不希望由于网络拥塞导致哨兵错误认为主服务器宕机而用宝贵的时间和资源执行选举算法并重新启动主数据节点；另一方面，我们也不希望宕机的主节点迟迟无法被监测到使得Redis更新操作效率大打折扣。平衡取舍，我们将宕机时长设置为500ms。

##### 5.3.5 Shortage on Redis Cluster

Redis Cluster is not able to guarantee strong consistency. In practical terms this means that under certain conditions it is possible that Redis Cluster will lose writes that were acknowledged by the system to the client. Thereason why Redis Cluster can lose writes is because it uses asynchronous replication. Although no crash happens, if redis client asks data for the slave nodes, then consistence can not be guaranteed. To overcome this problem, continuous procedures are expected to detect this exception. After all, this kind of exception happens at a pretty low frequency.

#### 5.4 Token Bucket Algorithm

<img src="%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%BC%80%E9%A2%98%E8%AE%BA%E6%96%87.assets/image-20191214201050745.png" alt="image-20191214201050745" style="zoom:47%;" />

令牌桶算法主要用于限流。令牌以恒定速度生成加入到令牌桶，每个请求在获得令牌后才可以继续处理业务逻辑，没有获得令牌的请求被直接拒绝。使用令牌桶算法有两个原因：

1. 限制并发流量，可以将最大流量维持到一个现有服务器处理能力的上限；
2. 相比于其他限流算法，有应对突发流量的能力，秒杀前可以先装满令牌桶到达处理能力上限，保证吞吐率；

- 功能接口

  - boolean RedisPool.acquireToken()：申请一个令牌，成功返回true，否则返回false

- 方法实现：

  - TokenBucket私有类

    由于操纵令牌桶的是单机单进程，所以没必要单独设置锁，利用java的synchronized特性，保证同一时刻只有一个线程可以操纵tokens变量即可。

    ```java
    class TokenBucket{
        private Integer tokens=50000;
        private static Integer maxTokens = 500000;
    
        public synchronized Integer getToken(){
            return tokens;
        }
    
        synchronized void incrToken(){
            if(tokens<maxTokens)
                ++tokens;
        }
    
        synchronized boolean decrToken(){
            if(tokens<=0)
                return false;
            --tokens;
            return true;
        }
    }
    ```

  - RedisPool类涉及令牌桶的方法：

    利用@Scheduled注解，调用定时方法

    ```java
        // 每1ms，令牌桶中令牌增加一个，可以根据服务器处理能力进行调整
    	@Scheduled(fixedRate = 1)
        private static void incrTokenBucket(){
            bucket.incrToken();
        }
    
        public static boolean acquireToken(){
            return bucket.decrToken();
        }
    ```

    

#### 5.5 Redisson

Redis原生的事务特性是基于乐观锁和CAS机制实现的，这在本项目中产生两个问题：

1. 乐观锁不适用于高并发的场景，大量的Redis更新请求会被废弃，浪费CPU和内存资源；
2. 简单的CAS机制容易产生ABA问题，即事务1执行开始时确定数据为A，在执行过程中事务2更改数据为B，事务3再更改其为A，事务1提交更新的时候比对无误提交成功，但实际上数据已经是脏数据。

基于这两个原因，尤其是第一个原因，我们放弃使用Redis原生的事务特性，改为使用基于Redis的分布式框架Redisson.

##### 5.5.1 Redisson 加锁与释放

​	Redisson加锁实际上是通过Redis 的eval指令执行lua脚本来实现的。Redisson加锁基本思路为设置一个hset，key为锁ID，field为主机UUID加上线程UUID，value为锁的重入锁。为避免死锁，锁有一定的超时期限，超时自动释放。为了避免业务逻辑没完成，锁就已经超时，Redisson设置了watchdog，每到超时期限的1/3，就监测锁是否仍被占有，如果仍被占有就刷新锁的超时时间。

```lua
"if (redis.call('exists', KEYS[1]) == 0) then " +
                  "redis.call('hset', KEYS[1], ARGV[2], 1); " +
                  "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                  "return nil; " +
              "end; " +
              "if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " +
                  "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
                  "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                  "return nil; " +
              "end; " +
              "return redis.call('pttl', KEYS[1]);"
```

1. 如果通过 `exists` 命令发现当前 key 不存在，即锁没被占用，则执行 `hset` 写入 Hash 类型数据 **key:全局锁名称**（例如共享资源ID）, **field:锁实例名称**（Redisson客户端ID:线程ID）, **value:1**，并执行 `pexpire` 对该 key 设置失效时间，返回空值 `nil`，至此获取锁成功。

2. 如果通过 `hexists` 命令发现 Redis 中已经存在当前 key 和 field 的 Hash 数据，说明当前线程之前已经获取到锁，因为这里的锁是**可重入**的，则执行 `hincrby` 对当前 key field 的值**加一**，并重新设置失效时间，返回空值，至此重入获取锁成功。

3. 最后是锁已被占用的情况，即当前 key 已经存在，但是 Hash 中的 Field 与当前值不同，则执行 `pttl` 获取锁的剩余存活时间并返回，至此获取锁失败

类似Redisson加锁，Redisson释放锁也是通过lua脚本来完成的：

```lua
 "if (redis.call('exists', KEYS[1]) == 0) then " +
                        "redis.call('publish', KEYS[2], ARGV[1]); " +
                        "return 1; " +
                    "end;" +
                    "if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then " +
                        "return nil;" +
                    "end; " +
                    "local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); " +
                    "if (counter > 0) then " +
                        "redis.call('pexpire', KEYS[1], ARGV[2]); " +
                        "return 0; " +
                    "else " +
                        "redis.call('del', KEYS[1]); " +
                        "redis.call('publish', KEYS[2], ARGV[1]); " +
                        "return 1; "+
                    "end; " +
                    "return nil;",
```

1. key 不存在，说明锁已释放，直接执行 `publish` 命令发布释放锁消息并返回 `1`。

2. key 存在，但是 field 在 Hash 中不存在，说明自己不是锁持有者，无权释放锁，返回 `nil`。

3. 因为锁可重入，所以释放锁时不能把所有已获取的锁全都释放掉，一次只能释放一把锁，因此执行 `hincrby` 对锁的值**减一**。

4. 释放一把锁后，如果还有剩余的锁，则刷新锁的失效时间并返回 `0`；如果刚才释放的已经是最后一把锁，则执行 `del` 命令删除锁的 key，并发布锁释放消息，返回 `1`。

- Function Interface

### 6. Kafka

#### 6.1 Kafka简介

#### Introduction to Kafka

Kafka是一个分布式的基于Zookeeper协调的发布订阅系统。

Kafka is a distributed publish-subscribe system accordinated with Zookeeper.

主要应用场景: 日志收集系统与消息系统。

It is widely used in log collecting system or serves as a highly efficent message queue.

Kafka主要设计目标：

Principles of Kafka:

- 以O(1)时间复杂度提供消息持久化的能力，对TB级别的数据也能保证常数时间的访问性能。

High efficiency： ability to provide data persitency with extremely high efficiency, can access TB level of data in constant time complexity. 

- 高吞吐率。在廉价机器上也能做到单机支持100K/s速率的消息传输

High throuthput: support message transport with at the speed of 100 K/s on a cheap machine. 

- 支持消息分区，以及分布式消费。可以保证每个分区内部消息的顺序传输

Partitioning and distributed consuming: guarantee that each message is transported in order within each partition

- 同时支持离线数据处理与实时数据处理

The ability of online and offline data processing

#### 6.2 发布订阅消息系统

#### Publish - subscribe message system

![img](https://images2018.cnblogs.com/blog/1228818/201805/1228818-20180507190443404-1266011458.png)

图片ref:https://images2018.cnblogs.com/blog/1228818/201805/1228818-20180507190443404-1266011458.png

Kafka是一种发布-订阅消息系统，所谓发布订阅系统，指的是发布者不直接把信息发给消费者，发布者把消息持久化到一个topic中。与点对点消息系统不同的是，消费者可以订阅一个或者多个topic，消费者可以消费该topic中所有的数据，而且同一条数据可以被多个消费者消费。发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息。

As we mention above, Kafka is a publish-subscribe system, which means the publisher does not have to send the message to consumer, directly. Instead, message sent by the publicher can be persited in a topic. Furthermore, in contrast of the point-2-point message system, consumers can subscribe more than one topic simultaneously.In other words, one single data can be consumed by multiple consumers. Only those consumers which have already subscribed the specific topics can receive the messages.


#### 6.3 Kafka在本项目中的作用

#### Usage of Kafka in this project

- 解耦

- Decoupling

解耦指的是在项目启动的时候，难以预测未来的具体需求。那么消息系统可以在处理过程中插入一个隐含的，基于数据的接口，两边的处理过程都要实现这个接口。

Decoupling means that sometimes it is hard to predict the future demand in specfic, especially upon the beginning of the project. So message queue like Kafka can serve as a implicit, data-based interface between the other middlewares.

具体在本项目中，解耦具体表现在订单访问redis预减库存量以及最终访问数据库库存量之间。

To be more specfic, this project use Kafka to decouple the process between redis and mysql. When successfully pre-decreasing the stock number in redis, the process with automaically start a new thread to send the data to Kafka. Finally, the Kafka consumer listener thread will detect a new data in the queue and send it to mysql, tring to update the final stock number in mysql.

- 削峰

- despiking

Sometimes in occasions where the amount of data will increase rapidly like seckilling system， message queue can serves as a powerful buffer-like middleware. The main goal of our system is to minimize the request sent to the mysql simultaneously, cause it may cause heavy overhead or even deadlock when mysql handle vast amount of request. So by using Kafka, requests will be enqueued quickly but dequeued slowly, so the pressure of mysql can be reduced. In a word, despiking with Kafka can decrease the possibility that the whole system would crash.

削峰指有时候数据量会剧增，那么如果以处理这类峰值访问为标准来投入资源，会造成巨大的浪费。因此使用消息队列能够使得关键组件顶住突发的访问压力，使得系统不会因为突发的超负荷请求而完全崩溃。

具体在本项目中，削峰体现在大量的秒杀请求入队然后通过消息队列缓慢出队，以减少对数据库访问的压力。

- 可扩展性

- scalability

The broker number can be easily adjusted according to the amount of requests.

消息队列解耦了消息处理过程，所以使得调节消息处理速度也变得更加方便。可以通过简单改变集群数，分区数就可以轻易地增大消息入队和处理的频率。

- 异步通信

- Asynchronous communication

Asynchronous communication means producer does not have to wait for the consumer to respond the message sent to it. Instead, the producer will continue to send messages regardless of the sending result. Compared with synchronous communication, it certainly boost the efficieny of message processing.

异步通信指消费者有时候不想立刻处理生产者发来的消息，因此消息队列提供了异步处理机制。允许用户把一个消息放入队列，但是不立即处理。

具体在本项目中，体现在把整个下单访问数据库的过程异步化，每个请求的成功访问与否互不关联，提高了消息处理的效率。

#### 6.4 Kafka基本概念

- Basic concepts of Kafak

- Broker

Kafka cluster container multiple server nodes, namelyy broker. Each broker save the topic's partition data.

kafka集群中包括多个服务器，单个服务器节点即broker. broker存储着topic的partition数据

- Topic

Each message sent to kafka cluster is assigned to a topic. Topic serves as a logically message set, here the word "logically" means that multiple partition datas within a single topic are stored in different brokers.But for the consumer, it does not have to care about where the data is stored.

每一条发布到Kafka集群的消息都有一个类别，即Topic. 属于逻辑上的消息集合概念，实际物理上同一个Topic的多个分区数据可能是存储在不同broker上的，但是对使用者来说不必关心数据存于何处

- Partition

Datas within one single topic are stored in more than one paritions. Inside each partition, the datas are stored with multiple segments.Furthermore, data withn a single partition can be consumed by strict order.

topic中的数据实际上会分布在一个或者多个partition上存储。每个分区中的数据使用多个segment文件存储。分区内的数据可以保证有序性。

- Producer

The responsibiliy of producer is to send the message to a specific topic in Kafka. Broker will automatically append the newly-incoming data to the segment.

消息的发布者，角色把消息发布到Kafka的topic中，broker接收到生产者发送的消息后，broker会把消息**追加**到当前用于存储数据的segment中。

- Consumer

Consumer is responsible for reading the data of the topic, we try to use spring-kafka , a package highly coupled with Spring-Boot. When the seckilling service starts, it will start a new consumer listener thread. To increase the consuming speed, we also start a threadpool to multiplex the consumer thread. 

消费者负责从broker中读取topic数据，本项目中采用spring-kafka，在秒杀服务启动的时候会额外启动一个消费者监听线程，负责监听Kafka集群中的分区，消费数据。

#### 6.5 Kafka在本项目中的部署与参数配置优化

#### Deployment of Kafka and optimization of configuration.

本项目在五台服务器上共搭建5节点的Kafka Broker与ZooKeeper集群

Following are the server name, ip address and basic configuration of the 5 servers we use.


| 服务器 | ip          | 配置         |
| ------ | ----------- | ------------ |
| admin  | 172.101.8.2 | 8cpu 16G内存 |
| node1  | 172.101.8.3 | 8cpu 16G内存 |
| node2  | 172.101.8.4 | 8cpu 16G内存 |
| node3  | 172.101.8.5 | 8cpu 16G内存 |
| node4  | 172.101.8.6 | 8cpu 16G内存 |



Kafka Broker配置优化：

Optimization of server configuration of Kafka 

```markdown
# 用于接受并处理网络请求的线程数，默认为3，实际上为Kafka内部轮询机制中负责读取请求的线程数。
# 本项目由于上下游并发请求量过大，因此为了尽可能减少io等待，配置线程数量为cpu核数+1
num.network.threads=9
```


```markdown
# 负责磁盘io操作的线程数，默认为8，因为Kafka生产和消费过程中都会伴随着
# 数据的落盘，为了提高入队和出队的速率，可以适当增加处理磁盘的io线程数
num.io.threads=16
```


```markdown
# 每隔1s就刷写一次磁盘
log.flush.interval.ms=1000
```


```Markdown
# 设定发送消息后不需要Broker端返回确认，虽然存在丢失数据的风险，但是由于本项目对数据完整性以及数据消费顺序没有要求，因此吞吐量能达到最大
acks: 0
```
#### Implementation of Kafka

* Producer

kafkaProducer.java

We implement a static method 'sendMessage', and the code logic is quite simple.We just need to send the message to the assigned topic.

```
 public static void sendMessage(Map<String, String> topicMsg) throws Exception {
 
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);
        for (Map.Entry<String, String> entry : topicMsg.entrySet()) {
            String topic = entry.getKey();
            String msg = entry.getValue();
            ProducerRecord<String, String> record = new ProducerRecord<String, String>(topic, msg);
            producer.send(record);
        }
```


* Consumer

We initially implement two version:

First version: miaoshaConsumer.java

We use the spring-kafka package, which is highly coupled wihh Spring Boot.When service starts, it will start a listener thread with the concurrency of 100.It will keep polling the remote Kafka cluster and try to get the enqueued message, then send it to Mysql for update.

We need to override the listen method of the spring-kafka KafkaListener, basic logic is:
1.get the message from the topic
2.deserialize the json-like message to object
3.mannually commit the offset

```
 @KafkaListener(containerFactory = "batchFactory", group = "test-consumer-group", topics={"mykafka"})
    public void listen(List<ConsumerRecord<String, String>> records, Acknowledgment ack) throws Exception {
        try {
            for (ConsumerRecord<?, ?> record : records) {
                Optional<?> kafkaMessage = Optional.ofNullable(record.value());
                // 获取消息
                String message = (String) kafkaMessage.get();
                // 反序列化
                Stock stock = gson.fromJson((String) message, Stock.class);
                orderService.createOrderAndSendToDB(stock);
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            ack.acknowledge();
        }
    }
```
For further configuration, we can use the kafkaFactory Bean.

Here we set up the basic config, concurrency number and batch consumption mode.
```
@Bean
    KafkaListenerContainerFactory<?> batchFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(new DefaultKafkaConsumerFactory<>(consumerConfigs()));
        factory.setBatchListener(true);
        factory.setConcurrency(100);
        factory.setAutoStartup(true);
        factory.getContainerProperties().setAckMode(AbstractMessageListenerContainer.AckMode.MANUAL_IMMEDIATE);
        return factory;
    }
```

Second version:

kafkaConsume.java

Similarly, we start a Consumer thread upon the beginnning of the seckilling service. Here we use a thread-pool to initiate 100 threads, each of which is responsible for handling the messages coming from one partition.We also set the kafka to commit offsets manually and enable batch consumption.

```
public class kafkaConsumer {

    private ExecutorService threadPool;

    private List<kafkaConsumeTask> consumeTaskList;

    public kafkaConsumer(int threadNum) throws Exception{
        ThreadFactory threadFactory = new ThreadFactoryBuilder()
                .build();
        threadPool = new ThreadPoolExecutor(threadNum, threadNum, 0L, TimeUnit.MILLISECONDS, new
                LinkedBlockingDeque<Runnable>(1024), threadFactory, new ThreadPoolExecutor.AbortPolicy());
        consumeTaskList = new ArrayList<kafkaConsumeTask>(threadNum);

        for(int i=0;i<threadNum;i++) {
            kafkaConsumeTask consumeTask = new kafkaConsumeTask(i);
            consumeTaskList.add(consumeTask);
        }
    }

    public void execute() {
        for(kafkaConsumeTask task:consumeTaskList) {
            threadPool.submit(task);
        }
    }
}
```

KafkaConsumeTask.java

Each thread is 'assigned' to a single partition. 

```
public class kafkaConsumeTask implements Runnable {

    private KafkaConsumer<String, String> consumer;
    
    public kafkaConsumeTask(int partitionIdx) {
        consumer = new KafkaConsumer<String, String>(properties);
        TopicPartition topicPartition = new TopicPartition(topic, partitionIdx);
        consumer.assign(Arrays.asList(topicPartition));
    }


    @Override
    public void run() {
        while(true) {
            ConsumerRecords<String, String> records = consumer.poll(200);
            for(ConsumerRecord<String, String> record : records) {
                try {
                    System.out.printf("thread = %s, offset = %d, key = %s, partition = %s, " +
                            "value = %s \n", Thread.currentThread().getName(),
                            record.offset(), record.key(), record.partition(), record.value());
                    processMessage(record.value());
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }
```

So at the beginning of the project, we create a consumer object and run the execute method, then a total amount of 100 threads will listen to its own partition separately.

```
 kafkaConsumer consumer=new kafkaConsumer(100);
 consumer.execute();
```


During Experiment, we find out that the first version has a serious problem of consumption backlog.And the consumption speed is quite slow. While the consumption speed of second version is relatively satisfactory and enough to handle the vast amount of requests.


### 7. 性能瓶颈,问题分析与解决方案
### Bottleneck of the seckilling system

#### 问题1：Kafka消费速度过慢及产生消费挤压问题

Problem 1: Kafka consuming speed is slow and the occurance of consumption backlog

At the beginning, the partition number of Kafka clusters is set to 5, meaning that each node is responsible for a single partition.We find out that with this configuration, the enqueing speed is much faster than the dequeing speed, vast amount of http requests are backloged wihtin Kafka. The unsatisfactory result of the extremely-slow consumption speed it that the goods can not be sold out immediately, violating the basic principles of a seckilling system.

刚开始测试的时候，Kafka集群的分区数量为5，大概每一个节点负责维护1个分区。这就导致了进队速度远远大于出队速度，导致大量HTTP请求产生了积压。

架构改进前：

Before improvement of the architecture

We use optimistic concurrency control based on version number to avoid over-selling, 

具体来说，我们采取的是基于版本号的乐观并发更新机制，意味着每个HTTP请求都会伴随一个版本号，每个HTTP请求生成的时候都会去Redis请求获得当前的版本号。只有在当前版本号与当前Mysql记录的版本号相等的HTTP请求才能成功触发库存的更新，更新成功后才会去更新Mysql和Redis版本号。

举个例子，试想如果生产速度远远高于消费速度，假设现在最新的版本号为1，那么在时刻t1产生的5000个请求都会在Redis请求当前的版本号，所以这5000个请求的版本号都为1. 那么第一个出队的HTTP的请求会成功触发Mysql库存更新，版本号更新为2。但是接下来的时间都是用来处理剩下的4999个请求，这4999个请求由于版本号为1，所以更新失败。所以系统大量时间浪费在处理无效的对Mysql访问的HTTP请求，导致新的版本号对应的请求无法及时访问Mysql，导致秒杀商品难以迅速售光。

架构改进后：

After improvement of the architecture

这时候因为Redis已经扛住了大量的无效请求，所以发送给Kafka的请求量其实并不大。因此对消费速度的要求其实并不高。

Since Redis has already stop the majority of invalid request, the number of requests sent to kafka is actually quite small.So Kafka is no longer the bottleneck of the project anymore.

提升Kafka消费速度的解决方案：

Solution to boostig the consumption speed of Kafka

- 增加分区数量，结合线程池进行多线程消费

- increasing the partition number, consume with multithread based on thread-pool

We try to increase the partition number from 5 to 100, each node handles 20 paritions on average. Theoretically, the throughput of Kafka is proportional to the number of partitions, thus the consumption speed will be higher. Furthermore, with more partitions, the pressure of handling messages will be reduced for each partition. It is less likely for consumption logback to happen.We replace the single-thread kafka listener with a thread-pool solution, each consumption thread is responsible for handling requests coming from a single partition.

分区数量从5个增加到100个，平均每个服务器节点handle20个分区。理论上分区数目越多，kafka的吞吐量会越大，处理消息的速度也会越快。因为分区越多，间接减少了单个分区的消息负载的压力，减少了单个分区消费积压发生的可能性。在增大分区后，生产者还是随机把秒杀请求分发到100个分区，而原来的Kafka监听单线程改写为使用线程池，开启100个监听线程，每个消费线程具体负责消费1个分区的HTTP请求。

- 消费者关闭auto commit自动提交偏移量选项

- set the enable-auto-commit option as false 

Since the update of parition offset concerns with Network IO, we can instead commit the offset manually so as to reduce the overhead of network IO and relieve the pressure of bandwidth, thus increasing the consumption speed.

设置enable-auto-commit:false

分区偏移量的更新涉及到网络的IO，因此可以选择手动提交偏移量offset，以减少网络IO开销，减轻带宽压力，进而提高消费速度。

- 分批消费消息，增加单次拉取消息的大小

- Consume the message in batch size

We modify the max-pool-records option as 10000, which means we can process at most 10000 requests in each single IO.Thus the IO number can be sharply reduced and consumption speed is again boosted.

修改max-poll-records为10000，即单次消费数据最大条数为10000.

并且把逐条消费数据改为分批消费数据，每次网络IO能处理更多的消费量，同样减少了消费者的IO次数，提高了消费速度。

- 生产者采取消息序列化与压缩算法

- Producer serialie the requests with efficient compression algorithm

First we can serilaize the json-object like HTTP request as byte stream to minimize the size of the message.Also, Kafka has many  high-efficient built-in compression algorithm to further reduce the size of the daat.Here we use gzip algorithm since its compression performance stands out most.

首先把Json格式的HTTP请求序列化为字节流，减少要传递的消息大小。并且kafka在消息传递的时候内置支持了许多压缩算法，这里采用压缩性能比最高的gzip算法。从而能够减少通信的开销。

- 在Kafka属性配置文件中调参
- Optimization in the server.properties of Kafka producer

We have discussed this part above.The main goal can be summarized as :

* Increasing the thread num of IO processing

* Reduce the size of message we need to transport

* Sacrifice the orderness of messages for higher throughout

详细介绍见Kafka在本项目中的部署与参数配置优化一节中的介绍，核心思想就是通过增加IO处理的线程数量，减少传输次数与传输的数据量量以减轻网络带宽的压力，以及牺牲数据的完整性有序性来换取尽可能高的吞吐量。

With above optimziation, we find out that the consumption performance is boosted heavily, and we also solve the consumption logback problem. 

Actually, the biggest bottleneck of the system is network bandwidth.Since we initially deploy our service locally, while the middlewares like redis and kafka are deployed on the campus's servers. Service deployed locally have to send the RESTful request to remote server, this may cause a great deal of time.So we decide to deploy the seckilling service on remote server where serive itself along with Kafka,Redis and Mysql are withn the same LAN. The test result shows that the performance of remotely deploy version is 3-4 times better than the local version. 

经过上述优化后，消费速度提升非常明显，能够较好地解决消费滞后和消费挤压问题，库存商品卖不完的问题也得到了解决。

经分析，网络带宽才是我们的整个项目的性能最大瓶颈。因为我们的秒杀服务一开始是在本地部署的，而中间件都是部署在学校的服务器，本地部署的秒杀服务把Restful请求传输到远程服务器上，这段时间开销比较大。后来当把秒杀服务部署到远程服务器后，秒杀服务与Kafka，Redis和Mysql同在一个局域网内，因此网络io速度也大大提高，经测试，秒杀完成速度提高了3-4倍。


#### 问题2： 改进前架构没有充分利用Redis

This problem has been discussed in 4.1.

#### 问题3： 高并发下的JVM调优

JVM optimization with high concurrency

在测试的时候，发现由于大量线程对象的生成导致堆内存空间压力比较大，经常导致秒杀服务崩溃的情况，因此要对JVM的参数调优：

During experiment, we also find out that the serive would crash occasionally, since hadnling large amount of thread simultaneously will definitely pose huge pressure on the JVM heap space. And the production of vase amount of objects also means we need to take garbage collection (GC) into consideration.

The solution we come forward can be summaried as:

1.优化虚拟机堆的空间大小，并根据实际物理内存的大小进行比例分配，并且，堆不进行自动扩展。然后使用ParNew+CMS进行垃圾回收。

1.Optimize the heap space size, allocating the heap space with the memory we have (16G). And we stop the auto-expanding of the heap to reduce overhead. Finally we choodse ParNew + CMS(Concurrent Mark Sweep) algorithm to perform GC.

2.一个线程都有一个对应的线程栈区，可以考虑减小单个线程栈区的大小，使得在相同的物理内存下可以提高产生的线程数量。

2.Since each thread has it own thread stack, we can reduce the stack size of each thread, so with same memory we can produce more thread.

3.尽可能使得垃圾回收发生在新生代，减少老生代GC的次数，进而提高程序的影响速度和吞吐量。

3.Make sure garbage collection happens in young generation, minimize the number of GC in old generation so as to boost the respond speed and throughput of the system.

4.大量线程对象的生成同时也意味着大量垃圾的产生，因此要修改垃圾回收策略，尽可能提高新生代垃圾回收的效率。

4.Optimize the garbage collection policy to improve the efficiency of GC in young generation.

具体配置：
Configuration:

```
-XX:+UseParallelGC：代表垃圾回收策略为并行收集器(吞吐量优先)，即在整个扫描和复制过程采用多线程的方式来进行，适用于多CPU、对暂停时间要求较短的应用上
```

```
-XX:ParallelGCThreads=8：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。配置为单机处理器数目8
```

```
-XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例
```

```
-Xmx10g 

设置Java虚拟机的堆的最大可用内存大小，尽可能将对象预留在新生代，减少老年代GC的次数（通常老年回收起来比较慢）。实际工作中，通常将堆的初始值和最大值设置相等，这样可以减少程序运行时进行的垃圾回收次数和空间扩展，从而提高程序性能;

-Xms10g

设置Java虚拟机的堆的初始值内存大小，设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存;

-Xmn4g 

设置年轻代内存大小;

-Xss3k

设置每个线程的栈大小。在相同物理内存下，减小这个值能生成更多的线程;

```


#### 问题4： 高并发下基于Redission 实现的分布式锁失效

Problem 4: Failing of Redis lock based on Redission with relatively high concurrency.

During experiemnt, we find out that when we test the system with relatively high concurrency, like more than 10000 HTTP requests per second, the concurrecny control with Redis lock will fail working. To be specfic, during the test we find out that sometimes the system may oversell the products of one or two.  We guessed that is is probably caused by the third-party package Redission we use, maybe it it is not that reliable as its official website have claimed. 

We come out a super tricky solution to this problem:

By changing the mysql update query from :

```
"UPDATE stock SET count = count - 1, sale = sale + 1 WHERE " +
            "id = #{id, jdbcType = INTEGER}"
```

to:

```
"UPDATE stock SET count = count - 1, sale = sale + 1 WHERE " +
            "id = #{id, jdbcType = INTEGER}" AND count > 0 "

```

By adding "AND count > 0", the stock number will be constrained as semi-positive forever.


### 8. Nginx

tbc..


### 9. 测试方案

### Test Plan

本项目使用Apache Jmeter来模拟大量的HTTP请求

In this project, we use Apache Jmeter to simulate vase amount of HTTP requests sent to the seckilling system.

jmx配置：模拟生成1千万个http请求,产生http请求的速度制约于秒杀系统的性能。

Configuration of jmx file: We simultaneously produce 10 million HTTP request in 10 seconds, the speed of producing http is propotional to the performance of the seckilling system.

Test result:

架构改建前：

Before improvement:

- Redis缓存+Kafka削峰+Mysql乐观锁更新方案：
- Solution with Redis+Kafka+Mysql(Optimistic lock)
  maximum tps: 600/s before the products are sold out, 1300/s after sold out.

  最高tps：秒杀过程中600/s,库存为0之后继续访问的请求tps1300/s

- Redis缓存+Kafka削峰+Mysql乐观锁更新+Nginx分发到7台服务器方案
- Solution with Redis+Kafka+Mysql(Optimistic lock)+ Nginx proxy to 7 machines
  maximum tps:  1000/s before the products are sold out, 2500/s after sold out.
  
  最高tps:  秒杀过程中tps1000/s，库存为0之后继续访问的请求tps2500/s

架构改进后：

- Redis缓存+Kafka削峰+Redis分布式锁 秒杀服务单机部署：

- Solution with Redis+Kafka+Redis distributed lock+ nginx proxy to 7 machines

- maximum tps:  16000-18000/s
  最高tps： 16000-18000/s

- Redis缓存+Kafka削峰+Zookeeper分布式锁 秒杀服务单机部署：

- Solution with Redis+Kafka+Zookeeper distributed lock+ nginx proxy to 7 machines

- maximum tps:  16000-18000/s
  最高tps： 16000-18000/s

### 结论

### Solution

tbc...

### 附录：程序使用
#### How to start the Service

* Deploy locally

1.run startApplication.java

2.open http://localhost:8088/swagger-ui.html#/ to test your Restful API.


* Deploy on server

1.Package the project into a jar

2.upload to server

3.run 

```
java -jar your-jar.jar 
```

4.open http://your-server-ip-address:8088/swagger-ui.html#/ to test your Restful API.

#### How to use Jmeter to test

1. start a thread group

![](https://raw.githubusercontent.com/daydreamdev/MeetingFilm/master/pic/seconds-kill/1.png)

2. modify thread Num 

![](https://github.com/daydreamdev/MeetingFilm/raw/master/pic/seconds-kill/2.png)

3. add HTTP request

![](https://raw.githubusercontent.com/daydreamdev/MeetingFilm/master/pic/seconds-kill/3.png)

4.modify your service address, port, parameter

![](https://github.com/daydreamdev/MeetingFilm/raw/master/pic/seconds-kill/4.png)

5.Add summary report

![](https://github.com/daydreamdev/MeetingFilm/raw/master/pic/seconds-kill/5.png)

Finally, go to swagger-ui website and run /checkStock api to see whether your stock has been sold out all.



### Ref

tbc...

